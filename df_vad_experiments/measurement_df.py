import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import torch
from df.enhance import enhance, init_df, load_audio, save_audio
from df.utils import download_file

def visualize_and_save(original_path, enhanced_path, output_png):
    """ë‘ ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì½ì–´ íŒŒí˜•ê³¼ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì„ ë¹„êµ ì €ì¥í•©ë‹ˆë‹¤."""
    
    # ë°ì´í„° ë¡œë“œ
    y1, sr1 = librosa.load(original_path)
    y2, sr2 = librosa.load(enhanced_path)
    
    plt.figure(figsize=(16, 10))

    # --- 1. ì›ë³¸ (Noisy) ì‹œê°í™” ---
    # íŒŒí˜•
    plt.subplot(2, 2, 1)
    librosa.display.waveshow(y1, sr=sr1, color='gray', alpha=0.8)
    plt.title('Original (Noisy) Waveform')
    
    # ìŠ¤í™íŠ¸ë¡œê·¸ë¨
    plt.subplot(2, 2, 3)
    D1 = librosa.stft(y1)
    S_db1 = librosa.amplitude_to_db(np.abs(D1), ref=np.max)
    librosa.display.specshow(S_db1, sr=sr1, x_axis='time', y_axis='hz', cmap='magma')
    plt.title('Original Spectrogram')

    # --- 2. ë³´ì •ë³¸ (Enhanced) ì‹œê°í™” ---
    # íŒŒí˜•
    plt.subplot(2, 2, 2)
    librosa.display.waveshow(y2, sr=sr2, color='#800080') # ë³´ë¼ìƒ‰
    plt.title('Enhanced (DeepFilterNet2) Waveform')
    
    # ìŠ¤í™íŠ¸ë¡œê·¸ë¨
    plt.subplot(2, 2, 4)
    D2 = librosa.stft(y2)
    S_db2 = librosa.amplitude_to_db(np.abs(D2), ref=np.max)
    librosa.display.specshow(S_db2, sr=sr2, x_axis='time', y_axis='hz', cmap='magma')
    plt.title('Enhanced Spectrogram')

    plt.tight_layout()
    plt.savefig(output_png, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š ì‹œê°í™” ì´ë¯¸ì§€ê°€ '{output_png}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    plt.show()

if __name__ == "__main__":
    # 1. DeepFilterNet ëª¨ë¸ ì´ˆê¸°í™”
    model, df_state, _ = init_df()
    
    # 2. ì˜¤ë””ì˜¤ íŒŒì¼ ì¤€ë¹„ (ì‚¬ìš©ìì˜ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì • ê°€ëŠ¥)
    # ì˜ˆì‹œë¥¼ ìœ„í•´ ì›ê²© íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì§€ë§Œ, ë³¸ì¸ì˜ íŒŒì¼ì´ ìˆë‹¤ë©´ ê²½ë¡œë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.
    audio_path = "before_deepfilter.wav"
    
    # 3. ì˜¤ë””ì˜¤ ë¡œë“œ ë° ê°•í™”(Denoise) ì²˜ë¦¬
    audio, _ = load_audio(audio_path, sr=df_state.sr())
    enhanced = enhance(model, df_state, audio)
    
    # 4. ê²°ê³¼ íŒŒì¼ ì €ì¥
    enhanced_wav_path = "enhanced_result.wav"
    save_audio(enhanced_wav_path, enhanced, df_state.sr())
    print(f"âœ… ê°•í™”ëœ ì˜¤ë””ì˜¤ê°€ '{enhanced_wav_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 5. ì‹œê°í™” ë° PNG ì €ì¥ ì‹¤í–‰
    visualize_and_save(audio_path, enhanced_wav_path, "comparison_result.png")